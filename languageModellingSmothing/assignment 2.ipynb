{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import random\n",
    "import nltk\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textProc(file_name):\n",
    "    f= open(file_name,'r')\n",
    "    #tp1\n",
    "    corpus = f.read().replace('\\n',' ') #replace the new line with single white space.\n",
    "    corpus = corpus.lower() #tp2\n",
    "\n",
    "    token = sent_tokenize(corpus)\n",
    "\n",
    "    #replace all the non alphanumeric characters with whitespace.\n",
    "    token = [re.sub(r'[^A-Za-z0-9]',\" \", i) for i in token]#tp3\n",
    "\n",
    "    random.shuffle(token)\n",
    "\n",
    "    #addtG(token) #add tags\n",
    "    return token\n",
    "\n",
    "    #clean tokens of sentence returned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#write a function for count of n-gram\n",
    "def LstOfNgram(count,corpus):\n",
    "    #cleaned corpus\n",
    "    n_gram=[]\n",
    "    for i in corpus:\n",
    "        p = word_tokenize(i)\n",
    "        p = [\"<s>\"]+p\n",
    "        p.append(\"</s>\")    \n",
    "        #token must have start and end line tags here.\n",
    "        #print (p)\n",
    "        for g in range(count-1,len(p)):\n",
    "            dummy=\"\"\n",
    "            for j in range(count):\n",
    "                dummy = p[g-j]+\" \"+dummy   #i,i-1,i-2,i-3,i-4,i-5,...,i-(n-1)\n",
    "               #more things to be added here\n",
    "            dummy = re.sub(r\"^\\s|\\s$\",\"\",dummy)\n",
    "            n_gram.append(dummy)\n",
    "    return (n_gram)    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> this is', 'this is a', 'is a sentence', 'a sentence </s>']\n"
     ]
    }
   ],
   "source": [
    "p = [\"this is a sentence\"]\n",
    "o = LstOfNgram(3,p)\n",
    "print (o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CountNgram(frequency):\n",
    "    count ={}\n",
    "    \n",
    "    for (key,fvalue) in reversed(sorted(frequency.items(), key = itemgetter(1))):\n",
    "        count[key] = fvalue\n",
    " \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unified method for MLE of n-gram\n",
    "def MLE(a,b,N):  #n is N of n-gram\n",
    "    try:\n",
    "        if N ==1:#unigram\n",
    "            return (count_unigram[a]/len(unigramLst))\n",
    "        elif N==2:#bigram\n",
    "            return (count_bigram[b+\" \"+a]/count_unigram[b])\n",
    "        elif N == 3:#triram\n",
    "            return (count_trigram[b+\" \"+a]/count_bigram[b])\n",
    "        elif N == 4:\n",
    "            return (count_quadgram[b+\" \"+a]/count_trigram[b])\n",
    "    except:\n",
    "            return 0 #0 probability if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_NLst(count_dict):#pass dicationary of word vs count.\n",
    "    #create counting list for \n",
    "    l = count_dict \n",
    "    l=list(l.values())\n",
    "    l.sort()\n",
    "    #we want a dictionary with {1:1,2:1,3:2,4:3,5:1}\n",
    "    d={}\n",
    "    for i in range(len(l)):\n",
    "        count =1\n",
    "        for j in range(i,0,-1):\n",
    "            if l[i] == l[j-1]:\n",
    "                count = count + 1\n",
    "            else:\n",
    "                break \n",
    "    \n",
    "        d[l[i]] = count\n",
    "    return (d)\n",
    "#takes O(n^2) which takes lot of time to execute.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class add1_smoothing_bigram:#old_count is the dictionary of count versus bigram/unigram\n",
    "    \n",
    "    def __init__(self,old_countUnigram, old_countBigram):\n",
    "        self.old_countUnigram = old_countUnigram.copy()\n",
    "        self.old_countBigram = old_countBigram.copy()\n",
    "        self.new_countBigram = old_countBigram.copy()\n",
    "#        print (self.new_countBigram)\n",
    "        self.countBigram()\n",
    "        \n",
    "        \n",
    "    def countBigram(self):\n",
    "           \n",
    "            for i in self.new_countBigram.keys():\n",
    "                a_,b_= i.split(\" \")[1],i.split(\" \")[0]\n",
    "                self.new_countBigram[i]=self.old_countUnigram[b_]*self.prob(a_,b_)\n",
    "                \n",
    "        \n",
    "    def prob(self,a,b): #P(a|b)\n",
    "            bigram = b+\" \"+a\n",
    "            unigram = b\n",
    "            try:\n",
    "                numerator = self.old_countBigram[bigram] +1\n",
    "            except :\n",
    "                numerator = 1\n",
    "            try:   \n",
    "                denominator = self.old_countUnigram[unigram] + len(self.old_countUnigram.keys()) #count_unigram is count of unigram(types in corpus)\n",
    "            except :\n",
    "                denominator = len(self.old_countUnigram.keys())\n",
    "            return (numerator/denominator)\n",
    "#assure once that it is len(count_bigam)      ,token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class goodTurning:\n",
    "    def __init__(self,count): \n",
    "        self.countNgram = count\n",
    "        self.dictN = get_NLst(self.countNgram)\n",
    "        self.keys = list(self.dictN.keys())    #[N1,N2,N3,N4,N5,N6,...]\n",
    "        self.values = list(self.dictN.values()) #count of N1,N2,N3,...\n",
    "        self.NewCount()\n",
    "    def NewCount(self):\n",
    "        self.newCount=self.countNgram.copy()\n",
    "        \n",
    "        for i in self.newCount.keys():\n",
    "            try:\n",
    "                self.newCount[i] = (self.newCount[i]+1)*(self.dictN[self.newCount[i]+1]/self.dictN[self.newCount[i]])\n",
    "            except:\n",
    "                intr= np.interp(float(self.newCount[i]),[float(j) for j in self.keys],[float(k) for k in self.values])\n",
    "                #intr= np.interp(l[i]+1,keys,values)\n",
    "\n",
    "                self.newCount[i] = (self.newCount[i]+1)*(intr/(self.dictN[self.newCount[i]]))\n",
    "            #new for the word with zero count \n",
    "\n",
    "        return self.newCount \n",
    "    \n",
    "    def smoothProb(self,a,token): \n",
    "        #token : total number of token of n-gram \n",
    "    \n",
    "        if  a not in self.countNgram.keys():\n",
    "            return (dictN[1]/len(token)) #count of 1 divided by total ngrams in the corpus\n",
    "        \n",
    "        else:\n",
    "            return (self.NewCount()[a]/len(token))\n",
    "#look over interpolation function\n",
    "#for Nc >Nc+1 it is too jumpy\n",
    "#the above probability may be wrong??\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "token = textProc('SherlockHomes.txt')\n",
    "\n",
    "\n",
    "train = token[:int(len(token)*0.8)]#80%\n",
    "test= token[int(len(token)*0.8):]#20%\n",
    "#print (token)\n",
    "#print (train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#n-gram count\n",
    "#token = [\"this is a sentence\",\"this is something differnt\",\"this is something differnt that this has happend\"]\n",
    "#list contining n-gram\n",
    "unigramLst = LstOfNgram(1,train)  ##the first number here representes the N of N-gram.\n",
    "bigramLst  = LstOfNgram(2,train)\n",
    "trigramLst = LstOfNgram(3,train)\n",
    "quadgramLst= LstOfNgram(4,train)\n",
    "#print (unigramLst)\n",
    "#  query for count of unigram only once\n",
    "feq  =  nltk.FreqDist(unigramLst)\n",
    "freq =  nltk.FreqDist(bigramLst)\n",
    "fre  =  nltk.FreqDist(trigramLst)\n",
    "fr   =  nltk.FreqDist(quadgramLst)\n",
    "\n",
    "#count_unigram={}\n",
    "count_unigram = CountNgram(feq)\n",
    "count_bigram = CountNgram(freq)\n",
    "count_trigram = CountNgram(fre)\n",
    "count_quadgram = CountNgram(fr)\n",
    "print (count_quadgram[\"of this strange affair\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE for unigram, bigram, trigrams and quadgrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013526449411079203 0.02702702702702703 0.3333333333333333 1.0\n"
     ]
    }
   ],
   "source": [
    "l1 = MLE('affair','',1)\n",
    "l2 = MLE('affair','strange',2)\n",
    "l3 = MLE('affair','this strange',3)\n",
    "l4 = MLE('affair','of this strange',4)\n",
    "print (l1,l2,l3,l4)\n",
    "#work to get the probability for a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing : ADD-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002798376941374003\n"
     ]
    }
   ],
   "source": [
    "#QUESTION 5\n",
    "ADD1 = add1_smoothing_bigram(count_unigram,count_bigram)\n",
    "newProb = ADD1.prob(\"affair\",\"strange\")\n",
    "#print (ADD1.new_countBigram)\n",
    "print(newProb)\n",
    "#work for sentence probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing : Good-turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_gram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-0fd64728bd88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount_gram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'count_gram' is not defined"
     ]
    }
   ],
   "source": [
    "print (count_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n-gram evalutation, how many n-grams are there\n",
    "#question 6 \n",
    "\n",
    "p = goodTurning(count_bigram)\n",
    "q = goodTurning(count_unigram)\n",
    "#goodTuning smooting trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (q.newCount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Constant value discounting in good-tunning, for count b/w 1 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smooth_count = p.newCount\n",
    "#print (smooth_count)\n",
    "print (count_bigram[\"roylott had\"] -smooth_count[\"roylott had\"])#n=1\n",
    "print (count_bigram['merry over'] - smooth_count['merry over'])#n=2\n",
    "print (count_bigram['glass of'] - smooth_count['glass of'])\n",
    "print (count_bigram['desire to'] - smooth_count['desire to'])\n",
    "print (count_bigram['be taken'] - smooth_count['be taken'])\n",
    "print (count_bigram['is this'] - smooth_count['is this'])\n",
    "print (count_bigram['the bird'] - smooth_count['the bird'])#n =7\n",
    "print (count_bigram['holmes said'] - smooth_count['holmes said'])\n",
    "print (count_bigram['until i'] - smooth_count['until i'])\n",
    "print (count_bigram['other side'] - smooth_count['other side'])\n",
    "#the vaue of d is not constant in this corpus, after smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_count = q.newCount\n",
    "#print (smooth_count)\n",
    "print (count_unigram['suggests'] -smooth_count['suggests'])#n=1\n",
    "print (count_unigram[ 'advanced'] - smooth_count[ 'advanced'])#n=2\n",
    "print (count_unigram['discovering'] - smooth_count['discovering'])\n",
    "print (count_unigram['remarks'] - smooth_count['remarks'])\n",
    "print (count_unigram['carrying'] - smooth_count['carrying'])\n",
    "print (count_unigram['belief'] - smooth_count['belief'])\n",
    "print (count_unigram['solution'] - smooth_count['solution'])#n =7\n",
    "print (count_unigram['finding'] - smooth_count['finding'])\n",
    "print (count_unigram['path'] - smooth_count['path'])\n",
    "print (count_unigram['feeling'] - smooth_count['feeling'])\n",
    "#the vaue of d is not constant in this corpus, after smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#question 7\n",
    "#inverse of all the probability product of bigrams in the test data\n",
    "def prePlexity(bigram_count,uigram_count): #for add1 they are the new counts\n",
    "#the bigramData is a dictionary with count of all the bigrams.    \n",
    "    N = len(bigram_count.keys())   #a dictionary\n",
    "    p=1\n",
    "    for i in bigram_count.keys:\n",
    "        prob = bigram_count[i]/unigram_count[i.split(\" \")[0]]\n",
    "        p=p*prob\n",
    "    perplex = (1/p)**(N)\n",
    "    return perplex\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perPlexity(data,n):#input data in form of sentence\n",
    "    #give a data in form of list of sentence\n",
    "    #N is the token\n",
    "    prob = 1\n",
    "    n=N\n",
    "    for i in data:\n",
    "        #i is a sentence\n",
    "        p = LstOfNgram(2,[i])\n",
    "        q = 1\n",
    "        for j in p:  \n",
    "           \n",
    "            q = q*MLE(j.split(\" \")[1],j.split(\" \")[0],2)\n",
    "           # print (q)\n",
    "            if (q == 0):\n",
    "                print (j)\n",
    "        prob = prob*q\n",
    "       # print (prob)\n",
    "    perpLxty = (1/prob)**N\n",
    "    return perPlexity\n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "print (count_bigram[\"egg that\"])\n",
    "for i in test:\n",
    "    l+=word_tokenize(i)\n",
    "N = len(l)\n",
    "perPlexity(test,N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rough work below[a]/count_unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l=\"<s>this is a sentence here is.</s>\"\n",
    "token = word_tokenize(l)\n",
    "#print (token)\n",
    "regx = re.compile(\"[a-z0-9]+ [a-z0-9]+\")\n",
    "r =re.findall(regx,l)\n",
    "p= [\"<s>this\", \"this is\",\"is a \",\"a sentence\",\"sentence here\",\"here is\",\"is. </s>\"]\n",
    "print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import re\n",
    "l = \"this is a sentence here is\"\n",
    "token1 = word_tokenize(l)\n",
    "token1 = [\"<s>\"]+token1\n",
    "token1.append(\"</s>\")\n",
    "n_gram = []\n",
    "n=2 #bigram \n",
    "#so keeping a sentence token is a good idea\n",
    "#for i in range(n-1,len(token)):#start with the n-1 of the n gram, so that it does not give any error\n",
    " #   n_gram.append(token[i-1]+\" \"+token[i])\n",
    "#print (n_gram)\n",
    "\n",
    "#for n gram              <s>this is a sentence here is</s>\n",
    "print (token1)\n",
    "for i in range(n-1,len(token1)):\n",
    "    p=\" \"\n",
    "    for j in range(n):\n",
    "       p = token1[i-j]+\" \"+p   #i,i-1,i-2,i-3,i-4,i-5,...,i-(n-1)\n",
    "       #more things to be added here\n",
    "    n_gram.append(p)\n",
    "#print (n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l={\"this\":4,\"is\":3,\"my\":4,\"country\":3,\"hello\":1,\"bitch\":2}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l=[1,2,3,3,4,4,4,5,5,5,5,5,5,7,8,8,10,10,10,11,12]\n",
    "l={\"this\":4,\"is\":3,\"my\":4,\"country\":3,\"hello\":1,\"bitch\":2}\n",
    "\n",
    "l=list(l.values())\n",
    "l.sort()\n",
    "\n",
    "#we want a dictionary with {1:1,2:1,3:2,4:3,5:1}\n",
    "d={}\n",
    "for i in range(len(l)):\n",
    "    count =1\n",
    "    for j in range(i,0,-1):\n",
    "        if l[i] == l[j-1]:\n",
    "            count = count + 1\n",
    "          \n",
    "        else:\n",
    "            break \n",
    "    \n",
    "    d[l[i]] = count\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l=[1,2,3,4,5]\n",
    "p=l.copy()\n",
    "p[0]= 2\n",
    "p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "l={\"this\":4,\"is\":3,\"my\":4,\"country\":3,\"hello\":1,\"bitch\":2}\n",
    "\n",
    "dictN = get_NLst(l)#dictionary of all the N's and corresponding values\n",
    "\n",
    "keys = list(dictN.keys())\n",
    "values = list(dictN.values())\n",
    "for i in l.keys():\n",
    "    try:\n",
    "       \n",
    "        l[i] = (l[i]+1)*(dictN[l[i]+1]/dictN[l[i]])\n",
    "    except:\n",
    "        intr = np.interp(l[i]+1,keys,values)\n",
    "        \n",
    "        l[i] = (l[i]+1)*(intr/dictN[l[i]])\n",
    "l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [\"<s>this is a sentence for me<\\s>\",\"<s>that is a sentence for you man<\\s>\"]\n",
    "#inverse of all the bigram probability to the power N,\n",
    "#probability of all the MLE birams\n",
    "#define a function that takes the sentences from the test data set and give out ptobability.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
