{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import random\n",
    "import nltk\n",
    "from operator import itemgetter\n",
    "import re\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textProc(file_name):\n",
    "    f= open(file_name,'r')\n",
    "    #tp1\n",
    "    corpus = f.read().replace('\\n',' ') #replace the new line with single white space.\n",
    "    corpus = corpus.lower() #tp2\n",
    "\n",
    "    token = sent_tokenize(corpus)\n",
    "\n",
    "    #replace all the non alphanumeric characters with whitespace.\n",
    "    token = [re.sub(r'[^A-Za-z0-9]',\" \", i) for i in token]#tp3\n",
    "\n",
    "    random.shuffle(token)\n",
    "\n",
    "    #addtG(token) #add tags\n",
    "    return token\n",
    "\n",
    "    #clean tokens of sentence returned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function for count of n-gram\n",
    "def LstOfNgram(count,corpus):\n",
    "    #cleaned corpus\n",
    "    n_gram=[]\n",
    "    for i in corpus:\n",
    "        p = word_tokenize(i)\n",
    "        p = [\"<s>\"]+p\n",
    "        p.append(\"</s>\")    \n",
    "        #token must have start and end line tags here.\n",
    "        #print (p)\n",
    "        for g in range(count-1,len(p)):\n",
    "            dummy=\"\"\n",
    "            for j in range(count):\n",
    "                dummy = p[g-j]+\" \"+dummy   #i,i-1,i-2,i-3,i-4,i-5,...,i-(n-1)\n",
    "               #more things to be added here\n",
    "            dummy = re.sub(r\"^\\s|\\s$\",\"\",dummy)\n",
    "            n_gram.append(dummy)\n",
    "    return (n_gram)    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CountNgram(frequency):\n",
    "    count ={}\n",
    "    \n",
    "    for (key,fvalue) in reversed(sorted(frequency.items(), key = itemgetter(1))):\n",
    "        count[key] = fvalue\n",
    " \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unified method for MLE of n-gram\n",
    "def MLE(a,b,N):  #n is N of n-gram\n",
    "    try:\n",
    "        if N ==1:#unigram\n",
    "            return (count_unigram[a]/len(unigramLst))\n",
    "        elif N==2:#bigram\n",
    "            return (count_bigram[b+\" \"+a]/count_unigram[b])\n",
    "        elif N == 3:#triram\n",
    "            return (count_trigram[b+\" \"+a]/count_bigram[b])\n",
    "        elif N == 4:\n",
    "            return (count_quadgram[b+\" \"+a]/count_trigram[b])\n",
    "    except:\n",
    "            return 0 #0 probability if not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_NLst(count_dict):#pass dicationary of word vs count.\n",
    "    #create counting list for \n",
    "    l = count_dict \n",
    "    l=list(l.values())\n",
    "    l.sort()\n",
    "    #we want a dictionary with {1:1,2:1,3:2,4:3,5:1}\n",
    "    d={}\n",
    "    for i in range(len(l)):\n",
    "        count =1\n",
    "        for j in range(i,0,-1):\n",
    "            if l[i] == l[j-1]:\n",
    "                count = count + 1\n",
    "            else:\n",
    "                break \n",
    "    \n",
    "        d[l[i]] = count\n",
    "    return (d)\n",
    "#takes O(n^2) which takes lot of time to execute.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class add1_smoothing_bigram:#old_count is the dictionary of count versus bigram/unigram\n",
    "    \n",
    "    def __init__(self,old_countUnigram, old_countBigram):\n",
    "        self.old_countUnigram = old_countUnigram.copy()\n",
    "        self.old_countBigram = old_countBigram.copy()\n",
    "        self.new_countBigram = old_countBigram.copy()\n",
    "#        print (self.new_countBigram)\n",
    "        self.countBigram()\n",
    "        \n",
    "        \n",
    "    def countBigram(self):\n",
    "           \n",
    "            for i in self.new_countBigram.keys():\n",
    "                a_,b_= i.split(\" \")[1],i.split(\" \")[0]\n",
    "                self.new_countBigram[i]=self.old_countUnigram[b_]*self.Prob(a_,b_,1)\n",
    "                \n",
    "        \n",
    "    def Prob(self,a,b,countBigram): #P(a|b)\n",
    "            bigram = b+\" \"+a\n",
    "            unigram = b\n",
    "            try:\n",
    "                numerator = self.old_countBigram[bigram] +1\n",
    "            except :\n",
    "                numerator = 1\n",
    "            try:   \n",
    "                denominator = self.old_countUnigram[unigram] + len(self.old_countUnigram.keys()) #types\n",
    "            except :\n",
    "                denominator = len(self.old_countUnigram.keys())\n",
    "            return (numerator/denominator)\n",
    "#assure once that it is len(count_bigam)    #see if it needs to be replaced by token?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class goodTuring:\n",
    "    def __init__(self,Bcount,Ucount): #dictionary of unigram and bigram count\n",
    "        self.biGramCount = Bcount.copy()\n",
    "        self.UniGramCount = Ucount.copy()\n",
    "        \n",
    "        self.bidictN = get_NLst(self.biGramCount)\n",
    "        self.UnidictN = get_NLst(self.UniGramCount)\n",
    "        \n",
    "        self.keysbi,self.valuesbi = list(self.bidictN.keys()),list(self.bidictN.values())    #[N1,N2,N3,N4,N5,N6,...]\n",
    "        self.keysuni,self.valuesuni = list(self.UnidictN.keys()),list(self.UnidictN.values()) #count of N1,N2,N3,...\n",
    "        \n",
    "        self.NewCountbi()\n",
    "        self.NewCountuni()\n",
    "    def NewCountbi(self):\n",
    "               \n",
    "        for i in self.biGramCount.keys():\n",
    "            try:\n",
    "                self.biGramCount[i] = (self.biGramCount[i]+1)*(self.bidictN[self.biGramCount[i]+1]/self.bidictN[self.biGramCount[i]])\n",
    "            except:\n",
    "                intr= np.interp(float(self.biGramCount[i]),[float(j) for j in self.keysbi],[float(k) for k in self.valuesbi])\n",
    "                #intr= np.interp(l[i]+1,keys,values)\n",
    "\n",
    "                self.biGramCount[i] = (self.biGramCount[i]+1)*(intr/(self.bidictN[self.biGramCount[i]]))\n",
    "            #new for the word with zero count \n",
    "\n",
    "        return self.biGramCount \n",
    "    def NewCountuni(self):\n",
    "               \n",
    "        for i in self.UniGramCount.keys():\n",
    "            try:\n",
    "                self.UniGramCount[i] = (self.UniGramCount[i]+1)*(self.UnidictN[self.UniGramCount[i]+1]/self.UnidictN[self.UniGramCount[i]])\n",
    "            except:\n",
    "                intr= np.interp(float(self.UniGramCount[i]),[float(j) for j in self.keysuni],[float(k) for k in self.valuesuni])\n",
    "                #intr= np.interp(l[i]+1,keys,values)\n",
    "\n",
    "                self.UniGramCount[i] = (self.UniGramCount[i]+1)*(intr/(self.UnidictN[self.UniGramCount[i]]))\n",
    "            #new for the word with zero count \n",
    "\n",
    "        return self.UniGramCount \n",
    "    \n",
    "    def Prob(self,a,b, tokenBigram):   #total number of bygram needs to be passed here\n",
    "        #token : total number of token of n-gram \n",
    "        bigram = b+\" \"+a\n",
    "        if bigram not in self.biGramCount.keys():\n",
    "            \n",
    "            return (self.bidictN[1]/len(tokenBigram))\n",
    "        \n",
    "        return self.biGramCount[bigram]/self.UniGramCount[b]\n",
    "#look over interpolation function\n",
    "#for Nc >Nc+1 it is too jumpy\n",
    "#the above probability may be wrong??\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def perPlexity(data,bigramLst,model):\n",
    "    log_perplxty = 0\n",
    "    for i in data:#data is the list of all the sentences \n",
    "        #i is a sentence\n",
    "        log_prob = 0\n",
    "        a = LstOfNgram(2,[i])\n",
    "        for i in a:\n",
    "            new = model.Prob(i.split(\" \")[1],i.split(\" \")[0],bigramLst)\n",
    "            #print(new)\n",
    "            log_prob = log_prob + math.log(new)\n",
    "            \n",
    "        log_perplxty = log_perplxty+log_prob\n",
    "        log_perplxty = (-1/len(data))*(log_perplxty)\n",
    "       \n",
    "    return (math.exp(log_perplxty) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token = textProc('SherlockHomes.txt')\n",
    "random.shuffle(token)\n",
    "\n",
    "train = token[:int(len(token)*0.8)]#80%\n",
    "test= token[int(len(token)*0.8):]#20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n-gram count\n",
    "\n",
    "#list contining n-gram\n",
    "unigramLst = LstOfNgram(1,train)  ##the first number here representes the N of N-gram.\n",
    "bigramLst  = LstOfNgram(2,train)\n",
    "trigramLst = LstOfNgram(3,train)\n",
    "quadgramLst= LstOfNgram(4,train)\n",
    "#print (unigramLst)\n",
    "#  query for count of unigram only once\n",
    "feq  =  nltk.FreqDist(unigramLst)\n",
    "freq =  nltk.FreqDist(bigramLst)\n",
    "fre  =  nltk.FreqDist(trigramLst)\n",
    "fr   =  nltk.FreqDist(quadgramLst)\n",
    "\n",
    "count_unigram = CountNgram(feq)\n",
    "count_bigram = CountNgram(freq)\n",
    "count_trigram = CountNgram(fre)\n",
    "count_quadgram = CountNgram(fr)\n",
    "#print (count_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90608\n"
     ]
    }
   ],
   "source": [
    "print (len(bigramLst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE for unigram, bigram, trigrams and quadgrams. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013950921906070734   0.010118785745710514   0.12871287128712872   0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "l1 = MLE('room','',1)\n",
    "l2 = MLE('room','the',2)\n",
    "l3 = MLE('room','into the',3)\n",
    "l4 = MLE('room', 'rushed into the',4)\n",
    "print (l1,\" \",l2,\" \",l3,\" \",l4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing : ADD-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#QUESTION 5\n",
    "ADD1 = add1_smoothing_bigram(count_unigram,count_bigram)\n",
    "newProb = ADD1.Prob(\"affair\",\"strange\",1)\n",
    "#print (ADD1.new_countBigram)\n",
    "#print(newProb)\n",
    "#print(count_bigram)\n",
    "#work for sentence probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing : Good-turing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n-gram evalutation, how many n-grams are there\n",
    "#question 6 \n",
    "\n",
    "p = goodTuring(count_bigram,count_unigram)\n",
    "\n",
    "#goodTuning smooting trained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GT_bigramCount = p.biGramCount\n",
    "GT_unigramCount = p.UniGramCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Constant value discounting in good-tunning, for count b/w 1 and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6857950395376163\n",
      "0.8314129775621588\n",
      "1.0464362850971924\n",
      "1.0778412039439544\n",
      "1.0464362850971924\n",
      "0.9744058500914079\n",
      "0.9744058500914079\n",
      "2.5064935064935066\n",
      "0.5982905982905979\n",
      "0.5982905982905979\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print (smooth_count)\n",
    "print (count_bigram[\"roylott had\"] -GT_bigramCount[\"roylott had\"])#n=1\n",
    "print (count_bigram['merry over'] - GT_bigramCount['merry over'])#n=2\n",
    "print (count_bigram['be taken'] - GT_bigramCount['be taken'])\n",
    "print (count_bigram[\"glass of\"] - GT_bigramCount[\"glass of\"])\n",
    "print (count_bigram['be taken'] - GT_bigramCount['be taken'])\n",
    "\n",
    "print (count_bigram['is this'] - GT_bigramCount['is this'])\n",
    "print (count_bigram['the bird'] - GT_bigramCount['the bird'])#n =7\n",
    "print (count_bigram['holmes said'] - GT_bigramCount['holmes said'])\n",
    "print (count_bigram['until i'] - GT_bigramCount['until i'])\n",
    "print (count_bigram['other side'] - GT_bigramCount['other side'])\n",
    "#the vaue of d is not constant in this corpus, after smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the constant value of d is close to 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity - Model Measure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0002383872811003\n",
      "1.0020284690912606\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BigramLst  = LstOfNgram(2,test)\n",
    "UnigramLst = LstOfNgram(1,test)\n",
    "Freq =  nltk.FreqDist(BigramLst)\n",
    "count_Bigram = CountNgram(Freq)\n",
    "l = perPlexity(BigramLst,bigramLst,p)\n",
    "print (l)\n",
    "m = perPlexity(BigramLst,bigramLst,ADD1)\n",
    "print (m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ADD-1 is a poor model compared to good turing accoring to the perplexity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rough work below[a]/count_unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is', 'a sentence', 'here is']\n"
     ]
    }
   ],
   "source": [
    "l=\"<s>this is a sentence here is.</s>\"\n",
    "token = word_tokenize(l)\n",
    "#print (token)\n",
    "regx = re.compile(\"[a-z0-9]+ [a-z0-9]+\")\n",
    "r =re.findall(regx,l)\n",
    "p= [\"<s>this\", \"this is\",\"is a \",\"a sentence\",\"sentence here\",\"here is\",\"is. </s>\"]\n",
    "print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'this', 'is', 'a', 'sentence', 'here', 'is', '</s>']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import re\n",
    "l = \"this is a sentence here is\"\n",
    "token1 = word_tokenize(l)\n",
    "token1 = [\"<s>\"]+token1\n",
    "token1.append(\"</s>\")\n",
    "n_gram = []\n",
    "n=2 #bigram \n",
    "#so keeping a sentence token is a good idea\n",
    "#for i in range(n-1,len(token)):#start with the n-1 of the n gram, so that it does not give any error\n",
    " #   n_gram.append(token[i-1]+\" \"+token[i])\n",
    "#print (n_gram)\n",
    "\n",
    "#for n gram              <s>this is a sentence here is</s>\n",
    "print (token1)\n",
    "for i in range(n-1,len(token1)):\n",
    "    p=\" \"\n",
    "    for j in range(n):\n",
    "       p = token1[i-j]+\" \"+p   #i,i-1,i-2,i-3,i-4,i-5,...,i-(n-1)\n",
    "       #more things to be added here\n",
    "    n_gram.append(p)\n",
    "#print (n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> this', 'this is', 'is a', 'a sentence', 'sentence </s>', '<s> and', 'and I', 'I am', 'am shoked', 'shoked that', 'that it', 'it is', 'is </s>', '<s> a', 'a sentence', 'sentence for', 'for you', 'you </s>']\n",
      "0.1875\n"
     ]
    }
   ],
   "source": [
    "#testing goods tuning\n",
    "l = [\"this is a sentence\",\"and I am shoked that it is\",\"a sentence for you\"]\n",
    "uni = LstOfNgram(1,l)\n",
    "bi = LstOfNgram(2,l)\n",
    "f = nltk.FreqDist(bi)\n",
    "feq  =  nltk.FreqDist(uni)\n",
    "count_unigr = CountNgram(feq)\n",
    "count_bi = CountNgram(f)\n",
    "p = goodTuring(count_bi,count_unigr)\n",
    "\n",
    "print (bi)\n",
    "print(p.Prob(\"is\",\"this\",bi))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
